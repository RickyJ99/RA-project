{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Cohmetrix output to csv\n",
    "Given as input the folder that contains the Cohmetrix output of our dataset (in this case only for the Trump dataset)\n",
    "the program returns a csv that merge the dataset of trump speech and the outcome for each speach in cohmetrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates found.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Label</th>\n",
       "      <th>DESPC</th>\n",
       "      <th>DESSC</th>\n",
       "      <th>DESWC</th>\n",
       "      <th>DESPL</th>\n",
       "      <th>DESPLd</th>\n",
       "      <th>DESSL</th>\n",
       "      <th>DESSLd</th>\n",
       "      <th>DESWLsy</th>\n",
       "      <th>DESWLsyd</th>\n",
       "      <th>DESWLlt</th>\n",
       "      <th>...</th>\n",
       "      <th>WRDCNCc</th>\n",
       "      <th>WRDIMGc</th>\n",
       "      <th>WRDMEAc</th>\n",
       "      <th>WRDPOLc</th>\n",
       "      <th>WRDHYPn</th>\n",
       "      <th>WRDHYPv</th>\n",
       "      <th>WRDHYPnv</th>\n",
       "      <th>RDFRE</th>\n",
       "      <th>RDFKGL</th>\n",
       "      <th>RDL2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>1.538</td>\n",
       "      <td>0.706</td>\n",
       "      <td>32.475</td>\n",
       "      <td>24.241</td>\n",
       "      <td>1.505</td>\n",
       "      <td>0.815</td>\n",
       "      <td>4.609</td>\n",
       "      <td>...</td>\n",
       "      <td>349.789</td>\n",
       "      <td>380.681</td>\n",
       "      <td>416.265</td>\n",
       "      <td>4.134</td>\n",
       "      <td>5.123</td>\n",
       "      <td>1.544</td>\n",
       "      <td>1.419</td>\n",
       "      <td>46.601</td>\n",
       "      <td>14.815</td>\n",
       "      <td>18.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>54.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>2849.0</td>\n",
       "      <td>2.556</td>\n",
       "      <td>1.341</td>\n",
       "      <td>20.652</td>\n",
       "      <td>12.926</td>\n",
       "      <td>1.514</td>\n",
       "      <td>0.849</td>\n",
       "      <td>4.569</td>\n",
       "      <td>...</td>\n",
       "      <td>362.049</td>\n",
       "      <td>395.614</td>\n",
       "      <td>432.946</td>\n",
       "      <td>4.268</td>\n",
       "      <td>5.314</td>\n",
       "      <td>1.543</td>\n",
       "      <td>1.622</td>\n",
       "      <td>57.796</td>\n",
       "      <td>10.327</td>\n",
       "      <td>16.536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>54.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>4.63</td>\n",
       "      <td>2.276</td>\n",
       "      <td>13.904</td>\n",
       "      <td>8.191</td>\n",
       "      <td>1.441</td>\n",
       "      <td>0.764</td>\n",
       "      <td>4.364</td>\n",
       "      <td>...</td>\n",
       "      <td>347.004</td>\n",
       "      <td>385.914</td>\n",
       "      <td>422.52</td>\n",
       "      <td>4.294</td>\n",
       "      <td>5.961</td>\n",
       "      <td>1.558</td>\n",
       "      <td>1.475</td>\n",
       "      <td>70.826</td>\n",
       "      <td>6.832</td>\n",
       "      <td>22.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>2.364</td>\n",
       "      <td>1.804</td>\n",
       "      <td>11.077</td>\n",
       "      <td>8.513</td>\n",
       "      <td>1.635</td>\n",
       "      <td>0.923</td>\n",
       "      <td>5.042</td>\n",
       "      <td>...</td>\n",
       "      <td>390.616</td>\n",
       "      <td>428.124</td>\n",
       "      <td>437.345</td>\n",
       "      <td>4.122</td>\n",
       "      <td>5.959</td>\n",
       "      <td>1.685</td>\n",
       "      <td>2.165</td>\n",
       "      <td>57.388</td>\n",
       "      <td>7.978</td>\n",
       "      <td>11.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>54.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>4.63</td>\n",
       "      <td>2.276</td>\n",
       "      <td>13.904</td>\n",
       "      <td>8.191</td>\n",
       "      <td>1.441</td>\n",
       "      <td>0.764</td>\n",
       "      <td>4.364</td>\n",
       "      <td>...</td>\n",
       "      <td>347.004</td>\n",
       "      <td>385.914</td>\n",
       "      <td>422.52</td>\n",
       "      <td>4.294</td>\n",
       "      <td>5.961</td>\n",
       "      <td>1.558</td>\n",
       "      <td>1.475</td>\n",
       "      <td>70.826</td>\n",
       "      <td>6.832</td>\n",
       "      <td>22.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>1.364</td>\n",
       "      <td>0.674</td>\n",
       "      <td>30.8</td>\n",
       "      <td>30.676</td>\n",
       "      <td>1.617</td>\n",
       "      <td>0.899</td>\n",
       "      <td>4.876</td>\n",
       "      <td>...</td>\n",
       "      <td>388.767</td>\n",
       "      <td>428.093</td>\n",
       "      <td>427.3</td>\n",
       "      <td>3.698</td>\n",
       "      <td>5.674</td>\n",
       "      <td>1.779</td>\n",
       "      <td>1.901</td>\n",
       "      <td>38.91</td>\n",
       "      <td>15.451</td>\n",
       "      <td>5.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>44.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2246.0</td>\n",
       "      <td>1.477</td>\n",
       "      <td>0.731</td>\n",
       "      <td>34.6</td>\n",
       "      <td>20.983</td>\n",
       "      <td>1.549</td>\n",
       "      <td>0.875</td>\n",
       "      <td>4.664</td>\n",
       "      <td>...</td>\n",
       "      <td>350.497</td>\n",
       "      <td>382.544</td>\n",
       "      <td>413.692</td>\n",
       "      <td>4.081</td>\n",
       "      <td>5.498</td>\n",
       "      <td>1.379</td>\n",
       "      <td>1.376</td>\n",
       "      <td>40.717</td>\n",
       "      <td>16.164</td>\n",
       "      <td>15.594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>1.083</td>\n",
       "      <td>0.289</td>\n",
       "      <td>40.308</td>\n",
       "      <td>30.184</td>\n",
       "      <td>1.613</td>\n",
       "      <td>0.995</td>\n",
       "      <td>5.006</td>\n",
       "      <td>...</td>\n",
       "      <td>384.898</td>\n",
       "      <td>422.092</td>\n",
       "      <td>440.842</td>\n",
       "      <td>4.273</td>\n",
       "      <td>6.147</td>\n",
       "      <td>1.49</td>\n",
       "      <td>2.133</td>\n",
       "      <td>29.619</td>\n",
       "      <td>19.103</td>\n",
       "      <td>12.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.699</td>\n",
       "      <td>28.286</td>\n",
       "      <td>23.272</td>\n",
       "      <td>1.639</td>\n",
       "      <td>0.964</td>\n",
       "      <td>4.913</td>\n",
       "      <td>...</td>\n",
       "      <td>383.162</td>\n",
       "      <td>424.723</td>\n",
       "      <td>454.258</td>\n",
       "      <td>3.916</td>\n",
       "      <td>5.406</td>\n",
       "      <td>1.584</td>\n",
       "      <td>1.862</td>\n",
       "      <td>39.828</td>\n",
       "      <td>14.643</td>\n",
       "      <td>11.246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>2.462</td>\n",
       "      <td>1.613</td>\n",
       "      <td>16.25</td>\n",
       "      <td>11.709</td>\n",
       "      <td>1.514</td>\n",
       "      <td>0.859</td>\n",
       "      <td>4.718</td>\n",
       "      <td>...</td>\n",
       "      <td>383.738</td>\n",
       "      <td>417.876</td>\n",
       "      <td>417.42</td>\n",
       "      <td>4.306</td>\n",
       "      <td>5.72</td>\n",
       "      <td>1.524</td>\n",
       "      <td>1.905</td>\n",
       "      <td>62.32</td>\n",
       "      <td>8.589</td>\n",
       "      <td>14.284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Label DESPC  DESSC   DESWC  DESPL DESPLd   DESSL  DESSLd DESWLsy DESWLsyd   \n",
       "7      26.0   40.0  1297.0  1.538  0.706  32.475  24.241   1.505    0.815  \\\n",
       "8      54.0  138.0  2849.0  2.556  1.341  20.652  12.926   1.514    0.849   \n",
       "9      54.0  250.0  3473.0   4.63  2.276  13.904   8.191   1.441    0.764   \n",
       "10     11.0   26.0   285.0  2.364  1.804  11.077   8.513   1.635    0.923   \n",
       "11     54.0  250.0  3473.0   4.63  2.276  13.904   8.191   1.441    0.764   \n",
       "..      ...    ...     ...    ...    ...     ...     ...     ...      ...   \n",
       "108    11.0   15.0   460.0  1.364  0.674    30.8  30.676   1.617    0.899   \n",
       "112    44.0   65.0  2246.0  1.477  0.731    34.6  20.983   1.549    0.875   \n",
       "117    12.0   13.0   522.0  1.083  0.289  40.308  30.184   1.613    0.995   \n",
       "118    10.0   14.0   391.0    1.4  0.699  28.286  23.272   1.639    0.964   \n",
       "122    13.0   32.0   518.0  2.462  1.613   16.25  11.709   1.514    0.859   \n",
       "\n",
       "Label DESWLlt  ...  WRDCNCc  WRDIMGc  WRDMEAc WRDPOLc WRDHYPn WRDHYPv   \n",
       "7       4.609  ...  349.789  380.681  416.265   4.134   5.123   1.544  \\\n",
       "8       4.569  ...  362.049  395.614  432.946   4.268   5.314   1.543   \n",
       "9       4.364  ...  347.004  385.914   422.52   4.294   5.961   1.558   \n",
       "10      5.042  ...  390.616  428.124  437.345   4.122   5.959   1.685   \n",
       "11      4.364  ...  347.004  385.914   422.52   4.294   5.961   1.558   \n",
       "..        ...  ...      ...      ...      ...     ...     ...     ...   \n",
       "108     4.876  ...  388.767  428.093    427.3   3.698   5.674   1.779   \n",
       "112     4.664  ...  350.497  382.544  413.692   4.081   5.498   1.379   \n",
       "117     5.006  ...  384.898  422.092  440.842   4.273   6.147    1.49   \n",
       "118     4.913  ...  383.162  424.723  454.258   3.916   5.406   1.584   \n",
       "122     4.718  ...  383.738  417.876   417.42   4.306    5.72   1.524   \n",
       "\n",
       "Label WRDHYPnv   RDFRE  RDFKGL    RDL2  \n",
       "7        1.419  46.601  14.815  18.434  \n",
       "8        1.622  57.796  10.327  16.536  \n",
       "9        1.475  70.826   6.832  22.757  \n",
       "10       2.165  57.388   7.978  11.783  \n",
       "11       1.475  70.826   6.832  22.757  \n",
       "..         ...     ...     ...     ...  \n",
       "108      1.901   38.91  15.451   5.601  \n",
       "112      1.376  40.717  16.164  15.594  \n",
       "117      2.133  29.619  19.103  12.394  \n",
       "118      1.862  39.828  14.643  11.246  \n",
       "122      1.905   62.32   8.589  14.284  \n",
       "\n",
       "[94 rows x 106 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def import_txt_files_to_dataframe(folder_path):\n",
    "\n",
    "    # Get a list of all the text files in the folder\n",
    "    files = []\n",
    "    for count in range(len(os.listdir(folder_path))):\n",
    "        path = folder_path + \"CohMetrixOutput (\" + str(count) + \").txt\"\n",
    "        files.append(path)\n",
    "\n",
    "    # Initialize an empty DataFrame\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # Iterate over each file\n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        \n",
    "        # Read the text file into a DataFrame\n",
    "        data = pd.read_csv(file_path, delimiter='\\t', index_col=False)\n",
    "\n",
    "        #taking only the colum Text and labele\n",
    "        data = data.iloc[:, [1,3]]\n",
    "\n",
    "        # Transpose the DataFrame and set row labels as column labels\n",
    "        data = data.T\n",
    "\n",
    "        # Reset the column labels to be the first row of the transposed DataFrame\n",
    "        data.columns =data.iloc[0]\n",
    "\n",
    "            # Remove the first row, which is now redundant as column labels\n",
    "        data =data[1:]\n",
    "                \n",
    "        # Append the data to the main DataFrame\n",
    "        df = pd.concat([df, data], ignore_index = True)\n",
    "    \n",
    "    return df\n",
    "def check_duplicates(dataframe):\n",
    "    # Check for duplicates in the DataFrame\n",
    "    duplicates = dataframe.duplicated()\n",
    "    \n",
    "    if duplicates.any():\n",
    "        # Get the duplicate rows\n",
    "        duplicate_rows = dataframe[duplicates]\n",
    "        print(\"Duplicate rows:\")\n",
    "        print(duplicate_rows)\n",
    "    else:\n",
    "        print(\"No duplicates found.\")\n",
    "\n",
    "# Provide the folder path containing the text files\n",
    "folder_path = '/Users/riccardodalcero/Library/CloudStorage/OneDrive-UniversitaCattolicaSacroCuore-ICATT/Materials/RA/Code_From Download to Dataset/Resources/Trump_Cohmetrix_Output/'\n",
    "\n",
    "# Call the function to import the text files into a DataFrame\n",
    "df = import_txt_files_to_dataframe(folder_path)\n",
    "\n",
    "#check duplicates\n",
    "check_duplicates(df)\n",
    "df[df.duplicated(subset=['DESPC'])] # True\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "#dataframe.to_csv('output.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "# Add a new column \"Record Order\" to the df dataframe representing the order of records\n",
    "df['Record Order'] = range(1, len(df) + 1)\n",
    "\n",
    "# Read the larger dataset CSV file\n",
    "df_1 = pd.read_csv(\"/Users/riccardodalcero/Library/CloudStorage/OneDrive-UniversitaCattolicaSacroCuore-ICATT/Materials/RA/Data/4_Data_with_AI_Market_Indicies.csv\", sep=\",\")\n",
    "\n",
    "# Convert the \"Date Time\" column to datetime format\n",
    "df_1[\"Date Time\"] = pd.to_datetime(df_1[\"Date Time\"], format=\"%Y-%m-%d %H:%M:%S%z\")\n",
    "\n",
    "# Filter the smaller dataset (trump_2020)\n",
    "trump_2020 = df_1[\n",
    "    (df_1[\"Date Time\"].dt.year == 2020)\n",
    "    & (df_1[\"Date Time\"].dt.month < 9)\n",
    "    & (df_1[\"Title\"].str.contains(\"Press Bri\"))\n",
    "    & (df_1[\"Administration\"].str.contains(\"Trump\"))\n",
    "].loc[:, :]\n",
    "\n",
    "trump_2020['Record Order'] = range(1, len(trump_2020) + 1)\n",
    "# Merge the two datasets using the \"Record Order\" column as the key\n",
    "merged_data = pd.merge(trump_2020, df, on='Record Order')\n",
    "merged_data\n",
    "count = 1\n",
    "for text in trump_2020.loc[trump_2020.index, \"Main text\"]:\n",
    "    \n",
    "    count+=1 \n",
    "    print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
